train = sample(392,196)
min(train)
max(train)
len(train)
shape(train)
size(train)
length(train)
colnames(mpg)
colnames(Auto)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
set.seed(1)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
mean((mpg - predict(lm.fit,Auto))[-train]^2)
Auto$
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
Auto$mpg
predict(lm.fit3,Auto)
predict(lm.fit3,Auto)
Auto$mpg
Auto$mpg [-train]
(Auto$mpg - predict(lm.fit3,Auto))[-train]
(Auto$mpg - predict(lm.fit3,Auto))[-train]^@
(Auto$mpg - predict(lm.fit3,Auto))[-train]^2''
(Auto$mpg - predict(lm.fit3,Auto))[-train]^2
(Auto$mpg - predict(lm.fit3,Auto))[-train]
(Auto$mpg - predict(lm.fit3,Auto))[-train]^2
(Auto$mpg - predict(lm.fit3,Auto))[-train]^2 %>% mean()
# Validation Set Approach
library(tidyverse)
library(ISLR)
set.seed(1)
# Get 196 random indexes
train = sample(392,196)
length(train)
# using Auto data and target variable is mpg
colnames(Auto)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
# Calculate MSE
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
# Validation Set Approach
library(tidyverse)
library(ISLR)
set.seed(2)
# Get 196 random indexes
train = sample(392,196)
length(train)
# using Auto data and target variable is mpg
colnames(Auto)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
# Calculate MSE
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
# Validation Set Approach
library(tidyverse)
library(ISLR)
set.seed(1)
# Get 196 random indexes
train = sample(392,196)
length(train)
# using Auto data and target variable is mpg
colnames(Auto)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
# Calculate MSE
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
# Validation Set Approach
library(tidyverse)
library(ISLR)
set.seed(1)
# Get 196 random indexes
train = sample(392,196)
length(train)
# using Auto data and target variable is mpg
colnames(Auto)
lm.fit  = lm(mpg~horsepower,data = Auto,subset = train)
summary(lm.fit)
# Calculate MSE
mean((Auto$mpg - predict(lm.fit,Auto))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower,2),data = Auto,subset = train)
lm.fit3  = lm(mpg~poly(horsepower,3),data = Auto,subset = train)
summary(lm.fit2)
summary(lm.fit3)
# Mean of Quadratic
mean((Auto$mpg - predict(lm.fit2,Auto))[-train]^2)
mean((Auto$mpg - predict(lm.fit3,Auto))[-train]^2)
library(boot)
library(ISLR)
glm.fit = glm(mpg~horsepower,data=Auto)
summary(glm.fit)
cv.err = cv.glm(Auto,glm.fit)
cv.err
cv.err$delta
?cv.glm
rep(0,5)
for (i in 1:5){
glm.fit = glm(mpg~poly(horsepower,i),data = Auto)
cv_array[i] = cv.glm(Auto,glm.fit)$delta[1]
}
cv_array
cv.err$delta
cv_array = rep(0,5)
for (i in 1:5){
glm.fit = glm(mpg~poly(horsepower,i),data = Auto)
cv_array[i] = cv.glm(Auto,glm.fit)$delta[1]
}
cv_array
for (i in 1:10){
glm.fit = glm(mpg~poly(horsepower,i),data = Auto)
cv_array[i] = cv.glm(Auto,glm.fit)$delta[1]
}
cv_array
# K-Fold Cross Validation
library(ISLR)
set.seed(17)
array_error = rep(0,10)
for (i in 1:10){
glm.fit = glm(mpg ~ poly(horsepower,i) , data = Auto)
array_error[i] = cv.glm(Auto,glm.fit,K=10)$delta[1]
}
array_error
# BootStrapping
library(ISLR)
alpha.fn = function(data,index){
X = data$X[index]
Y = data$Y[index]
return ((var(Y)-cov(X,Y)) / (var(X) + var(Y) - 2 * cov(X,Y)))
}
alpha.fn(Portfolio,1:100)
alpha.fn(Portfolio,sample(100,100,replace = T))
boot(Portfolio,alpha.fn,R=1000)
boot.fn(Auto,1:392)
boot.fn = function(data,index)
return (coef(lm(mpg~horsepower,data=data,subset = index)))
boot.fn(Auto,1:392)
boot.fn(Auto,sample(392,392,replace = TRUE))
boot.fn(Auto,sample(392,392,replace = TRUE))
boot(Auto,boot.fn,1000)
summary(lm(mpg~horsepower,data=Auto))$coef
?boot
boot.fn = function(data,index)
coefficients(lm(mpg~horsepower + I(horsepower^2),data=data,subset=index))
set.seed(1)
boot(Auto,boot.fn,1000)
summary(lm(mpg~horsepower + I(horsepower^2),data=data,subset=index))
summary(lm(mpg~horsepower + I(horsepower^2),data=Auto,subset=index))
summary(lm(mpg~horsepower + I(horsepower^2),data=Auto))
